version: "3"
services:
    mlops:
        build: .
        container_name: "inference"
        ports:
            - "8000:8000"